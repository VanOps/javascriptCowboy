# 02 Â· Copilot CLI CI Validator

> ğŸ¤” *Si Ollama requiere GPU o CPU potente para correr Llama, Â¿hay alternativa cloud que ya tengas incluida con tu suscripciÃ³n GitHub?*

**Respuesta**: **GitHub Copilot CLI**. Misma funcionalidad que el validador Ollama pero usando la infraestructura de GitHub. AdemÃ¡s, tiene acceso al contexto de tu repositorio.

---

## ComparaciÃ³n RÃ¡pida

| Aspecto | Ollama (Llama) | Copilot CLI |
|---------|:--------------:|:-----------:|
| Setup | Docker + modelo | 1 PAT token |
| Contexto | Solo input logs | Repo completo + GitHub |
| Velocidad | Tu CPU/RAM | Infraestructura GitHub |
| Costo | Gratis (hardware tuyo) | Incluido en Copilot |
| Offline | âœ… SÃ­ | âŒ No |

---

## ğŸ“ Estructura

```
.github/actions/copilot-ci-validator/
â”œâ”€â”€ action.yml
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ validator.js          â† Copilot CLI + tu JS
â”‚   â””â”€â”€ package.json
â””â”€â”€ examples/
    â””â”€â”€ k8s-crash.json
```

---

## 1. `action.yml`

```yaml
name: 'ğŸ¤– Copilot CLI CI Validator'
description: 'Valida CI/CD con GitHub Copilot CLI (logs K8s/Java/Python)'
inputs:
  context:
    description: 'JSON/TXT logs (K8s, build traces)'
    required: true
  prompt:
    description: 'InstrucciÃ³n para Copilot'
    required: true
  github-token:
    description: 'PAT con permisos Copilot'
    required: true
outputs:
  is-valid:
    description: 'true/false'
    value: ${{ steps.copilot-validator.outputs.is-valid }}
  analysis:
    description: 'AnÃ¡lisis detallado'
    value: ${{ steps.copilot-validator.outputs.analysis }}
  score:
    description: '0-100'
    value: ${{ steps.copilot-validator.outputs.score }}
runs:
  using: 'composite'
  steps:
    - name: ğŸŸ¢ Node.js 20.x
      uses: actions/setup-node@v4
      with:
        node-version: 20.x

    - name: ğŸ“¦ Install Copilot CLI
      run: npm i -g @github/copilot-cli
      shell: bash

    - name: ğŸ¤– Copilot CI Validation
      id: copilot-validator
      run: node ${{ github.action_path }}/src/validator.js
      shell: bash
      env:
        CONTEXT: ${{ inputs.context }}
        PROMPT: ${{ inputs.prompt }}
        GITHUB_TOKEN: ${{ inputs.github-token }}
        GITHUB_REPOSITORY: ${{ github.repository }}
```

---

## 2. `src/validator.js`

```javascript
// âœ… Modules + async/await + closures
import { exec } from 'child_process';
import { promisify } from 'util';
const execAsync = promisify(exec);

// âœ… CLOSURE: Cliente Copilot con cachÃ©
function createCopilotClient(githubToken) {
  const cache = new Map();  // ğŸ”’ Closure

  return async function(prompt, context) {
    const cacheKey = `${prompt.slice(0, 50)}`;

    if (cache.has(cacheKey)) {
      console.log('âœ… Copilot Cache HIT');
      return cache.get(cacheKey);
    }

    // âœ… TEMPLATE LITERAL: System prompt + context
    const fullPrompt = `@github/copilot-cli Analyze CI/CD logs:

CONTEXT:
${context}

TASK: ${prompt}

Output ONLY valid JSON:
{
  "isValid": true/false,
  "score": 0-100,
  "analysis": "detailed explanation",
  "actions": ["fix steps"]
}`;

    console.log('ğŸ¤– Copilot analyzing...');

    // âœ… ASYNC/AWAIT + child_process
    const { stdout } = await execAsync(`
      copilot --prompt "${fullPrompt.replace(/"/g, '\\"')}" \
        --allow-all-tools \
        --allow-all-paths \
        --github-token ${githubToken} < /dev/null
    `);

    // âœ… JSON parse
    const analysis = JSON.parse(stdout.trim());
    cache.set(cacheKey, analysis);

    return analysis;
  };
}

// âœ… DESTRUCTURING + main
const main = async () => {
  try {
    const { CONTEXT, PROMPT, GITHUB_TOKEN, GITHUB_REPOSITORY } = process.env;

    console.log('ğŸ” Repository:', GITHUB_REPOSITORY);
    console.log('ğŸ“‹ Context preview:', CONTEXT.slice(0, 200) + '...');

    const copilot = createCopilotClient(GITHUB_TOKEN);
    const analysis = await copilot(PROMPT, CONTEXT);

    // Outputs para workflow
    console.log(`::set-output name=is-valid::${analysis.isValid}`);
    console.log(`::set-output name=analysis::${analysis.analysis}`);
    console.log(`::set-output name=score::${analysis.score}`);

    console.log('âœ… Copilot analysis:', JSON.stringify(analysis, null, 2));

    if (!analysis.isValid) {
      console.error('âŒ Copilot rejected CI');
      process.exit(1);
    }
  } catch (error) {
    console.error('âŒ Copilot Error:', error.message);
    process.exit(1);
  }
};

main();
```

---

## ğŸ“Š Diagrama: ComparaciÃ³n Llama vs Copilot

```
                 MISMA INTERFAZ
                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                       â–¼
â”Œâ”€â”€â”€ OLLAMA/LLAMA â”€â”€â”€â”€â”  â”Œâ”€â”€â”€ COPILOT CLI â”€â”€â”€â”€â”
â”‚                      â”‚  â”‚                     â”‚
â”‚  fetch(localhost/    â”‚  â”‚  execAsync(          â”‚
â”‚    api/generate)     â”‚  â”‚    copilot --prompt) â”‚
â”‚                      â”‚  â”‚                     â”‚
â”‚  Modelo LOCAL        â”‚  â”‚  GitHub CLOUD        â”‚
â”‚  Tu CPU/RAM          â”‚  â”‚  + repo context     â”‚
â”‚  Offline âœ…          â”‚  â”‚  Online only         â”‚
â”‚                      â”‚  â”‚                     â”‚
â”‚  JSON response       â”‚  â”‚  JSON response      â”‚
â”‚  { isValid, score }  â”‚  â”‚  { isValid, score } â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                       â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
              MISMA SALIDA:
              ::set-output name=is-valid::true
              ::set-output name=score::85
```

---

## 3. Workflow de Uso

```yaml
name: ğŸ” Copilot K8s Validator
on: [push]

jobs:
  copilot-ci:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: ğŸ“‹ Capture K8s Logs
        id: logs
        run: |
          echo '{"error":"CrashLoopBackOff","pod":"mi-app-xyz","reason":"OOMKilled"}' > logs.json
          echo "context<<EOF" >> $GITHUB_OUTPUT
          cat logs.json >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: ğŸ¤– Copilot CI Gate
        uses: ./.github/actions/copilot-ci-validator
        id: copilot
        with:
          context: ${{ steps.logs.outputs.context }}
          prompt: |
            Analyze Kubernetes pod crash:
            1. Check OOMKilled/CrashLoopBackOff
            2. Memory/CPU limits exceeded?
            3. Missing configmaps/secrets?
            Should CI continue to deploy?
          github-token: ${{ secrets.COPILOT_GITHUB_TOKEN }}

      - name: ğŸš¦ Fail if Copilot says NO
        if: steps.copilot.outputs.is-valid != 'true'
        run: |
          echo "âŒ Copilot rejected:"
          echo "${{ steps.copilot.outputs.analysis }}"
          exit 1
```

---

## ğŸ”‘ Configurar PAT para Copilot

```
GitHub â†’ Settings â†’ Developer settings
â†’ Personal access tokens â†’ Fine-grained
â†’ Permissions: Copilot Requests: Read + Repository Read
â†’ Repo access: Solo tu repo
â†’ Copiar token â†’ Repo Settings â†’ Secrets â†’ COPILOT_GITHUB_TOKEN
```

---

## ğŸ¯ Flujo Completo Resumido

```
1. CI genera logs            â†’ context input
2. DevOps escribe prompt     â†’ "Â¿Es seguro hacer deploy?"
3. LLM analiza (Llama/Copilot) â†’ JSON estructurado
4. Action set-output         â†’ workflow decide pass/fail
5. CI gate                   â†’ bloquea deploy si LLM dice NO
```

---

## ğŸ› ï¸ Ejercicio Final

Implementa un workflow que:
1. Ejecute `npm test` y capture la salida
2. Pase los resultados al LLM Validator
3. Si el score < 70, bloquee el deploy
4. Si el score â‰¥ 70, despliegue a K8s staging

<details>
<summary>ğŸ” Ver esquema</summary>

```yaml
jobs:
  test:
    steps:
      - run: npm test 2>&1 | tee test-output.log
      - id: capture
        run: echo "context<<EOF" >> $GITHUB_OUTPUT && cat test-output.log >> $GITHUB_OUTPUT && echo "EOF" >> $GITHUB_OUTPUT

  validate:
    needs: test
    steps:
      - uses: ./.github/actions/llm-ci-validator
        with:
          context: ${{ needs.test.outputs.context }}
          prompt: "Analiza test results. Score < 70 = bloquear."
      - if: steps.llm.outputs.score < 70
        run: exit 1

  deploy:
    needs: validate
    steps:
      - run: kubectl apply -f k8s/ -n staging
```
</details>

---

[â¬…ï¸ Volver al mÃ³dulo](README.md) Â· [â¬…ï¸ Volver al Ã­ndice](../../README.md)
